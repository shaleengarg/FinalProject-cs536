{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "final project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dynamic-scanning"
      },
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "\n",
        "import math\n",
        "import copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from collections import Counter\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, invert_permutation\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0)"
      ],
      "id": "dynamic-scanning",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pregnant-government"
      },
      "source": [
        "assert torch.cuda.is_available(), 'GPU unavailable'"
      ],
      "id": "pregnant-government",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "55e73ae999b8942d37b609e25bd6f643",
          "grade": false,
          "grade_id": "cell-8a2c00bfecd1cc35",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thirty-coffee",
        "outputId": "74e9bb37-8cbd-4d86-9076-06434434cb6b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "id": "thirty-coffee",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SuMi8zuHjne",
        "outputId": "8d8a357c-12b1-44d3-a2ae-6fd577b6022b"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/ML_final_project/labeled_log-madbench_reformat.csv\", header = None)\n",
        "data = data.T.to_numpy()[1:6,:]\n",
        "print(data)\n",
        "window = 100\n",
        "data = np.hsplit(data, data.shape[1] / window)\n",
        "print(len(data))"
      ],
      "id": "_SuMi8zuHjne",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.51030000e+04 2.51060000e+04 2.51070000e+04 ... 2.51040000e+04\n",
            "  2.51040000e+04 2.51040000e+04]\n",
            " [1.20000000e+01 8.00000000e+00 8.00000000e+00 ... 1.00000000e+01\n",
            "  1.00000000e+01 1.00000000e+01]\n",
            " [1.35168000e+05 1.35168000e+05 1.35168000e+05 ... 6.68368896e+08\n",
            "  6.68401664e+08 6.68434432e+08]\n",
            " [4.09600000e+03 4.09600000e+03 4.09600000e+03 ... 4.09600000e+03\n",
            "  4.09600000e+03 4.09600000e+03]\n",
            " [1.00000000e+00 1.00000000e+00 1.00000000e+00 ... 1.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00]]\n",
            "52427\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUQfEYZSHlrl"
      },
      "source": [
        "def get_data_loader(data, batch_size):\n",
        "  random.shuffle(data)\n",
        "  data = np.array(data)\n",
        "  source_seq = data[:,:4,:]\n",
        "  target_seq = data[:,4:,:]\n",
        "\n",
        "  source_seq = torch.LongTensor(source_seq)\n",
        " \n",
        "  target_seq = torch.LongTensor(target_seq)\n",
        " \n",
        "  source_seq = source_seq.permute(0,2,1) #num_samples, seq_len, embedding_dim \n",
        "  target_seq = target_seq.permute(0,2,1) #num_samples, seq_len, 1 \n",
        "  train_set_size = int(0.9 * len(source_seq))\n",
        "\n",
        "  \n",
        "  train_set = TensorDataset(\n",
        "    source_seq[:train_set_size],\n",
        "    target_seq[:train_set_size])\n",
        "  \n",
        "  val_set = TensorDataset(\n",
        "    source_seq[train_set_size:],\n",
        "    target_seq[train_set_size:])\n",
        "  \n",
        "  loader_kwargs = {\n",
        "    'batch_size': batch_size,\n",
        "    'shuffle': True,\n",
        "    'num_workers': 4,\n",
        "    'pin_memory': True,\n",
        "    'drop_last': True,\n",
        "  }\n",
        "\n",
        "  train_loader = DataLoader(train_set, **loader_kwargs)\n",
        "  val_loader = DataLoader(val_set, **loader_kwargs)\n",
        "\n",
        "  return source_seq, target_seq, train_loader, val_loader"
      ],
      "id": "xUQfEYZSHlrl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB2J57ryIMaO",
        "outputId": "782301f8-1db7-478b-9e58-0b8fe36fa873"
      },
      "source": [
        "source_data, target_data, train_loader, val_loader = get_data_loader(\n",
        "  data, batch_size=40)\n",
        "print('source_data size:', source_data.size)\n",
        "print('target_data size:', target_data.size)\n",
        "\n",
        "print(source_data.shape)\n",
        "print(target_data.shape)"
      ],
      "id": "LB2J57ryIMaO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "source_data size: <built-in method size of Tensor object at 0x7f1ef66b7cd0>\n",
            "target_data size: <built-in method size of Tensor object at 0x7f1ef5342b90>\n",
            "torch.Size([52427, 100, 4])\n",
            "torch.Size([52427, 100, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "retained-mouth"
      },
      "source": [
        "source_seq,target_seq, train_loader, val_loader = get_data_loader(data, batch_size=100)"
      ],
      "id": "retained-mouth",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "96f3b5e3ce7e07c7537888b9111893c6",
          "grade": false,
          "grade_id": "cell-cc9b8ebc3255f311",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "natural-factory"
      },
      "source": [
        "class MultiHeadCausalSelfAttention(nn.Module):\n",
        "  \n",
        "  def __init__(self, d_model, num_heads, dropout=0.):\n",
        "    super().__init__()\n",
        "    \n",
        "    assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "    self.d_model = d_model\n",
        "    self.num_heads = num_heads\n",
        "    \n",
        "    # This dropout is to be applied to the attention weights\n",
        "    # immediately after the softmax. It was not mentioned\n",
        "    # in the paper, but is used in the actual implementation.\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    # The weight matrices of all heads are concatenated together\n",
        "    self.proj_q = nn.Linear(d_model, d_model, bias=False)\n",
        "    self.proj_k = nn.Linear(d_model, d_model, bias=False)\n",
        "    self.proj_v = nn.Linear(d_model, d_model, bias=False)\n",
        "    \n",
        "    self.proj_o = nn.Linear(d_model, d_model, bias=False)\n",
        "\n",
        "  \n",
        "  def forward(self, input):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "    - input: A Tensor of shape (batch_size, seq_len, d_model)\n",
        "      containing sequences of embeddings.\n",
        "    \n",
        "    Returns:\n",
        "    - output: A Tensor of shape (batch_size, seq_len, d_model)\n",
        "      containing the updated embeddings.\n",
        "    \"\"\"\n",
        "    #########################################################################\n",
        "    # TODO:                                                                 #\n",
        "    # Implement the forward pass. No for loop is allowed.                   #\n",
        "    # You may not use PyTorch's built-in multi-head attention.              #\n",
        "    #########################################################################\n",
        "    # Replace \"pass\" statement with your code\n",
        "    dk = torch.div(self.d_model,self.num_heads,rounding_mode=\"trunc\")\n",
        "  \n",
        "    dv  = dk\n",
        "    bs,sl ,_ = input.shape\n",
        "\n",
        "    \n",
        "    #split projection matrixes into h heads for parallel computation after projection\n",
        "    Q_concat = self.proj_q(input).view(bs,-1,self.num_heads,dk).transpose(1,2) #shape (bs,num_heads,seq_len,dk)\n",
        "    K_concat = self.proj_k(input).view(bs,-1,self.num_heads,dk).transpose(1,2)\n",
        "    V_concat = self.proj_v(input).view(bs,-1,self.num_heads,dv).transpose(1,2)\n",
        "    \n",
        "    #scaled dot-product attention to obtain raw scores\n",
        "    raw_score = torch.matmul(Q_concat, K_concat.transpose(-2,-1))/math.sqrt(dk)  #resulting shape (bs,num_heads,sl,sl)\n",
        "    # mask\n",
        "    attn_mask = torch.triu(\n",
        "    input.new_ones((sl, sl), dtype=torch.bool),\n",
        "    diagonal=1)\n",
        "    attn_mask = attn_mask.unsqueeze(0).unsqueeze(0)#view(bs, self.num_heads,sl,sl)\n",
        "    raw_score = raw_score.masked_fill(attn_mask == 1, -1e9)\n",
        "\n",
        "    #softmax \n",
        "    score = self.dropout(torch.softmax(raw_score, dim = -1))\n",
        "    \n",
        "    multihead_v = torch.matmul(score,V_concat) # resulting shape (bs,num_heads,sl,dv)\n",
        "    multihead_v = multihead_v.transpose(1,2).contiguous().view(bs,-1,self.d_model)  #(bs,sl,num_heads*dv)\n",
        "    output = self.proj_o(multihead_v)\n",
        "    \n",
        "\n",
        "\n",
        "    # END OF YOUR CODE\n",
        "    return output"
      ],
      "id": "natural-factory",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c6dafef5edd8bf1a54d170f26c1142ca",
          "grade": false,
          "grade_id": "cell-f2b92acd309534a2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "tutorial-hampton"
      },
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  \n",
        "  def __init__(self, d_model, num_heads, d_ff, dropout=0.):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.mulHeadAtt = MultiHeadCausalSelfAttention(d_model = d_model,num_heads= num_heads, dropout = dropout)\n",
        "    self.feedForward1 = nn.Linear(d_model,d_ff)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.feedForward2 = nn.Linear(d_ff,d_model) \n",
        "    self.layerNorm = nn.LayerNorm(d_model)\n",
        "  \n",
        "  \n",
        "  def forward(self, input):\n",
        "    x = input\n",
        "    output = self.mulHeadAtt(input)  # multihead causal self-attention  \n",
        "    output = self.dropout(output)  # dropout \n",
        "    output = output + x  # residual connection \n",
        "    output = self.layerNorm(output) # layer normalization \n",
        "    x = output \n",
        "    output = self.feedForward1(output)\n",
        "    output = self.relu(output)\n",
        "    output = self.feedForward2(output)\n",
        "\n",
        "    output = self.dropout(output)\n",
        "    output = x + output  \n",
        "    output = self.layerNorm(output)\n",
        "    return output"
      ],
      "id": "tutorial-hampton",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c3a4181842863c34d5926cdbe9189fa6",
          "grade": false,
          "grade_id": "cell-aff8acaf70d47322",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "academic-prototype"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "  \n",
        "  def __init__(self, max_len, d_model, dropout=0.):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    pos = torch.arange(max_len).unsqueeze(1).repeat(1,d_model)\n",
        "    #print(\"pos shape: \",pos.shape,\"max_len\",max_len)\n",
        "    assert pos.shape == torch.Size([max_len,d_model])\n",
        "    dim = torch.pow(10 , torch.arange(d_model)/d_model )\n",
        "    pe = pos / dim \n",
        "    pe[0::2] = torch.sin(pe[0::2])\n",
        "    pe[1::2] = torch.cos(pe[1::2])\n",
        "\n",
        "    pe = pe.unsqueeze(0)\n",
        "    self.register_buffer('pe',pe)\n",
        "\n",
        "  def forward(self, input):\n",
        "    bs, seq_len,d_model = input.shape\n",
        "    input = input*math.sqrt(d_model)\n",
        "    output = input + Variable(self.pe[:,:seq_len],requires_grad= False).cuda()\n",
        "\n",
        "    return output"
      ],
      "id": "academic-prototype",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "93f338ae2f405427c8fe0dd5464bb2c9",
          "grade": false,
          "grade_id": "cell-93007f53bbf3301b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "fluid-raise"
      },
      "source": [
        "class Transformer(nn.Module): # without embedding\n",
        "  \n",
        "  def __init__(self, num_blocks, label_classes, max_len, d_model, num_heads, d_ff, dropout=0.):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.label_classes = label_classes\n",
        "    self.num_heads = num_heads\n",
        "    self.d_ff = d_ff\n",
        "    self.max_len = max_len\n",
        "    self.num_blocks = num_blocks \n",
        "    self.PE = PositionalEncoding(max_len = max_len, d_model = d_model,dropout = dropout)\n",
        "    self.emd = nn.Embedding(label_classes, d_model,padding_idx = 0)\n",
        "    self.fullyConnect = nn.Linear(d_model,label_classes)\n",
        "    self.blocks = nn.ModuleList([TransformerBlock(d_model,num_heads,d_ff,dropout) for _ in range(num_blocks)])\n",
        "    #self.feedForward1 = nn.Linear(d_model,d_ff)\n",
        "    #self.relu = nn.ReLU()\n",
        "    #self.feedForward2 = nn.Linear(d_ff,label_classes)\n",
        "    \n",
        "  def forward(self, input,target):\n",
        "    PE_input = self.PE(input)\n",
        "    for i in range(num_blocks):\n",
        "      transBlock = self.blocks[i]\n",
        "      PE_input = transBlock(PE_input)\n",
        "    #  print(\"passed first transblock\") \n",
        "    \n",
        "    pred = self.fullyConnect(PE_input)\n",
        "    \n",
        "    #pred = self.fullyConnect(pred)  # bs,sel,vocab_size  raw output\n",
        "    target.squeeze(-1)\n",
        "    \n",
        "   # print(pred.shape)\n",
        "    target = target.squeeze()\n",
        "   # print(target.shape)\n",
        "    #print(\"visited\")\n",
        "    #weight = torch.cuda.FloatTensor([1,5])\n",
        "    CE = torch.nn.CrossEntropyLoss()\n",
        "    loss = CE(pred.reshape(-1,self.label_classes), target.reshape(-1))\n",
        "    return loss\n",
        "  \n",
        "  \n",
        "  def predict(self, input):\n",
        "    PE_input = self.PE(input)\n",
        "    for i in range(num_blocks):\n",
        "      transBlock = self.blocks[i]\n",
        "      PE_input = transBlock(PE_input)\n",
        "    # print(\"passed first transblock\")\n",
        "   \n",
        "    #output = self.feedForward1(PE_input)\n",
        "    #output = self.relu(output)\n",
        "    #pred = self.feedForward2(output) #out shape(bs,seq_len,voc_size) \n",
        "    pred = self.fullyConnect(PE_input)\n",
        "    pred = torch.argmax(pred, dim =2).squeeze()  # out shape (bs,seq_len,1)\n",
        "    # print(\"prediction shape: \", pred.shape)\n",
        "\n",
        "    return pred"
      ],
      "id": "fluid-raise",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9a19aebb8ef4a09bdad874b3160890c7",
          "grade": false,
          "grade_id": "cell-dc0757fbee6aabe2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "electronic-balance"
      },
      "source": [
        "def eval_acc(model, data_loader, num_samples=5):\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    \n",
        "    \n",
        "    total = 0\n",
        "    correct = 0\n",
        "    totalPositive = 0 \n",
        "    totalFalsePositive = 0\n",
        "    for batch, data in enumerate(data_loader):\n",
        "      data = [d.cuda() for d in data] # a data point consists of batches of input (bs, seq_len, d_model)and target (bs,seq_len,1)\n",
        "      \n",
        "    \n",
        "      pred = model.predict(data[0])\n",
        "      target = data[1]\n",
        "      #if batch < num_samples:  # show some samples\n",
        "        #target_sentence = [target_vocab.index2word[token] for token in data[0][0].tolist()]\n",
        "        #pred_sentence = [target_vocab.index2word[token] for token in pred[0].tolist()]\n",
        "        \n",
        "        #print(f'=== Sample {batch + 1} ===')\n",
        "        #print('target_sentence:', target_sentence)\n",
        "        #print('pred_sentence:  ', pred_sentence)\n",
        "      \n",
        "      total += target.view(-1).shape[0]\n",
        "      #num_of_ones = torch.count_nonzero(target.view(-1), dim=0)\n",
        "      \n",
        "      target = target.squeeze()\n",
        "      correct += (target == pred ).sum()\n",
        "      positive = pred[target ==1] \n",
        "      falsePositive = len(positive) - torch.count_nonzero(positive)\n",
        "      totalPositive += len(positive)\n",
        "      totalFalsePositive += falsePositive\n",
        "    #print(\"correct: \",correct)\n",
        "    #print(\"total: \", total)\n",
        "    acc = 100 * correct / total\n",
        "    #print(acc)\n",
        "    falsePositiveRate = totalFalsePositive/totalPositive\n",
        "    print(\"false Positive Rate is: \", falsePositiveRate.item())\n",
        "  return acc.item()"
      ],
      "id": "electronic-balance",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crazy-front"
      },
      "source": [
        "def train(model, train_loader, val_loader, num_epochs, learning_rate):\n",
        "  \n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  \n",
        "  loss_history = []\n",
        " \n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    val_acc = eval_acc(model, val_loader, num_samples=0)\n",
        "    \n",
        "    model.train()\n",
        "    for batch, data in enumerate(train_loader):\n",
        "      data = [d.cuda() for d in data]\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      loss = model(*data)\n",
        "      loss.backward()\n",
        "      clip_grad_norm_(model.parameters(), 1)  # gradient clipping\n",
        "      optimizer.step()\n",
        "      \n",
        "      with torch.no_grad():\n",
        "        loss_history.append(loss.item())\n",
        "        if batch == 0:\n",
        "          print('Train Epoch: {:3} \\t Loss: {:F} \\t Val Acc: {:F}'.format(\n",
        "            epoch, loss.item(), val_acc))\n",
        "  \n",
        "\n",
        "  return model, loss_history"
      ],
      "id": "crazy-front",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "canadian-fossil",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "423e0c5d-772a-4ccc-fd9b-01b06bcb467f"
      },
      "source": [
        "torch.manual_seed(1)\n",
        "\n",
        "batch_size = 80\n",
        "num_epochs = 50\n",
        "learning_rate = 1e-4\n",
        "#5e-4 78%\n",
        "\n",
        "num_blocks = 1\n",
        "d_model = 4\n",
        "num_heads = 1\n",
        "d_ff = 4 * d_model\n",
        "dropout = 0.3\n",
        "\n",
        "label_classes = 2 \n",
        "MAX_LEN = 100\n",
        "\n",
        "source_seq,target_seq, train_loader, val_loader = get_data_loader(data, batch_size)\n",
        "model = Transformer(num_blocks, label_classes, MAX_LEN, d_model, num_heads, d_ff, dropout)\n",
        "model = model.cuda()\n",
        "\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "model, loss_history = train(model, train_loader, val_loader, num_epochs, learning_rate)\n",
        "end = time.time()\n",
        "print(end - start)\n",
        "print((end - start)/20)"
      ],
      "id": "canadian-fossil",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "false Positive Rate is:  0.9616823792457581\n",
            "Train Epoch:   0 \t Loss: 0.764503 \t Val Acc: 10.546731\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:   1 \t Loss: 0.580147 \t Val Acc: 92.788467\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:   2 \t Loss: 0.427688 \t Val Acc: 92.772499\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:   3 \t Loss: 0.333148 \t Val Acc: 92.773659\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:   4 \t Loss: 0.293682 \t Val Acc: 92.771156\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:   5 \t Loss: 0.250782 \t Val Acc: 92.785774\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:   6 \t Loss: 0.275892 \t Val Acc: 92.787308\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:   7 \t Loss: 0.281274 \t Val Acc: 92.783272\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:   8 \t Loss: 0.272505 \t Val Acc: 92.822121\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:   9 \t Loss: 0.246748 \t Val Acc: 92.803848\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  10 \t Loss: 0.245301 \t Val Acc: 92.783081\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  11 \t Loss: 0.237161 \t Val Acc: 92.792122\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  12 \t Loss: 0.222514 \t Val Acc: 92.768654\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  13 \t Loss: 0.317985 \t Val Acc: 92.784615\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  14 \t Loss: 0.266776 \t Val Acc: 92.784424\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  15 \t Loss: 0.254460 \t Val Acc: 92.753845\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  16 \t Loss: 0.301827 \t Val Acc: 92.785965\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  17 \t Loss: 0.258361 \t Val Acc: 92.770966\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  18 \t Loss: 0.266422 \t Val Acc: 92.783463\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  19 \t Loss: 0.240578 \t Val Acc: 92.799423\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  20 \t Loss: 0.263678 \t Val Acc: 92.769043\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  21 \t Loss: 0.319476 \t Val Acc: 92.767311\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  22 \t Loss: 0.238924 \t Val Acc: 92.775192\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  23 \t Loss: 0.236068 \t Val Acc: 92.776733\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  24 \t Loss: 0.218679 \t Val Acc: 92.768654\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  25 \t Loss: 0.224321 \t Val Acc: 92.793274\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  26 \t Loss: 0.274001 \t Val Acc: 92.779427\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  27 \t Loss: 0.196987 \t Val Acc: 92.802696\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  28 \t Loss: 0.215191 \t Val Acc: 92.798851\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  29 \t Loss: 0.290575 \t Val Acc: 92.772118\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  30 \t Loss: 0.249712 \t Val Acc: 92.793083\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  31 \t Loss: 0.228395 \t Val Acc: 92.770195\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  32 \t Loss: 0.216007 \t Val Acc: 92.765770\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  33 \t Loss: 0.258316 \t Val Acc: 92.764618\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  34 \t Loss: 0.176300 \t Val Acc: 92.798080\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  35 \t Loss: 0.229196 \t Val Acc: 92.783081\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  36 \t Loss: 0.253406 \t Val Acc: 92.790192\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  37 \t Loss: 0.244929 \t Val Acc: 92.788658\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  38 \t Loss: 0.229723 \t Val Acc: 92.790771\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  39 \t Loss: 0.233008 \t Val Acc: 92.794235\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  40 \t Loss: 0.227435 \t Val Acc: 92.784424\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  41 \t Loss: 0.246420 \t Val Acc: 92.761353\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  42 \t Loss: 0.272424 \t Val Acc: 92.777695\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  43 \t Loss: 0.202512 \t Val Acc: 92.782310\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  44 \t Loss: 0.248766 \t Val Acc: 92.772308\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  45 \t Loss: 0.216179 \t Val Acc: 92.780769\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  46 \t Loss: 0.239138 \t Val Acc: 92.795006\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  47 \t Loss: 0.227714 \t Val Acc: 92.761353\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  48 \t Loss: 0.256887 \t Val Acc: 92.787888\n",
            "false Positive Rate is:  0.0\n",
            "Train Epoch:  49 \t Loss: 0.251412 \t Val Acc: 92.784233\n",
            "274.556036233902\n",
            "13.727801811695098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "decreased-percentage",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "ba9d664d-7ab1-43de-989d-e1df99643386"
      },
      "source": [
        "plt.plot(loss_history, 'o')\n",
        "plt.xlabel('Iteration number')\n",
        "plt.ylabel('Loss value')\n",
        "plt.show()"
      ],
      "id": "decreased-percentage",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "starting-plastic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fe96529-0c0d-4830-e8fe-a06af8279c6a"
      },
      "source": [
        "train_acc = eval_acc(model, train_loader)\n",
        "print('Training Accuracy:', train_acc)"
      ],
      "id": "starting-plastic",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "false Positive Rate is:  5.009726373828016e-05\n",
            "Training Accuracy: 52.39163589477539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "26c009e1905748bad2a3192323f36be8",
          "grade": true,
          "grade_id": "cell-6bab750be42b380e",
          "locked": true,
          "points": 45,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "fixed-ivory",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3bd2191-6227-4392-dd3f-985c9f69c30a"
      },
      "source": [
        "val_acc = eval_acc(model, val_loader)\n",
        "print('Validation Accuracy:', val_acc)\n",
        "assert val_acc >= 38"
      ],
      "id": "fixed-ivory",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "false Positive Rate is:  6.914991536177695e-05\n",
            "Validation Accuracy: 52.48508071899414\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3ihMsOoRV3w",
        "outputId": "9e3b3d8e-ff2b-4b5f-bfdd-595087cd35fe"
      },
      "source": [
        "model"
      ],
      "id": "X3ihMsOoRV3w",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (PE): PositionalEncoding(\n",
              "    (dropout): Dropout(p=0.3, inplace=False)\n",
              "  )\n",
              "  (emd): Embedding(2, 4, padding_idx=0)\n",
              "  (fullyConnect): Linear(in_features=4, out_features=2, bias=True)\n",
              "  (blocks): ModuleList(\n",
              "    (0): TransformerBlock(\n",
              "      (dropout): Dropout(p=0.3, inplace=False)\n",
              "      (mulHeadAtt): MultiHeadCausalSelfAttention(\n",
              "        (dropout): Dropout(p=0.3, inplace=False)\n",
              "        (proj_q): Linear(in_features=4, out_features=4, bias=False)\n",
              "        (proj_k): Linear(in_features=4, out_features=4, bias=False)\n",
              "        (proj_v): Linear(in_features=4, out_features=4, bias=False)\n",
              "        (proj_o): Linear(in_features=4, out_features=4, bias=False)\n",
              "      )\n",
              "      (feedForward1): Linear(in_features=4, out_features=16, bias=True)\n",
              "      (relu): ReLU()\n",
              "      (feedForward2): Linear(in_features=16, out_features=4, bias=True)\n",
              "      (layerNorm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OqeTC9zAPdK",
        "outputId": "9f5491be-625a-4c77-96e0-72fa3f3221e6"
      },
      "source": [
        "for param in model.parameters():\n",
        "  print(param)"
      ],
      "id": "1OqeTC9zAPdK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.4519, -0.1661, -1.5228,  0.3817]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.3437,  0.6721,  0.3051, -0.2518],\n",
            "        [-0.4575, -0.9761,  0.0482,  0.1917]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.6851,  0.5488], device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.2981,  0.2718, -0.4888,  0.3100],\n",
            "        [ 0.1397,  0.4743,  0.3300, -0.4556],\n",
            "        [-0.4754, -0.2412,  0.4391, -0.0833],\n",
            "        [ 0.2140, -0.2324,  0.4906, -0.2115]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.3750,  0.0059, -0.2634,  0.2570],\n",
            "        [-0.2654,  0.1471, -0.1444, -0.0548],\n",
            "        [-0.4807, -0.2384,  0.2713, -0.1215],\n",
            "        [ 0.4980,  0.4008, -0.0234, -0.3337]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.1179, -0.4499, -0.2774, -0.0596],\n",
            "        [ 1.0474,  1.2953, -0.3747,  0.6117],\n",
            "        [-0.9368, -0.8702, -0.2733, -1.1846],\n",
            "        [-0.0218, -0.3942,  0.2557, -0.0646]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.1129,  0.0349,  0.1316,  0.3174],\n",
            "        [-0.4234,  0.2725, -0.3305, -0.4131],\n",
            "        [-0.0756, -0.2103,  0.2203, -0.1788],\n",
            "        [-0.3911,  0.4588, -0.0339,  0.2110]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.2960, -0.3800,  0.2712, -0.1860],\n",
            "        [-0.3815, -0.3158,  0.3079, -0.0816],\n",
            "        [-0.1900, -0.0055,  0.3908, -0.0895],\n",
            "        [ 0.0319,  0.6062, -0.5985, -0.2835],\n",
            "        [ 0.2902, -0.3319,  0.1671,  0.6924],\n",
            "        [ 0.0501,  0.4461,  0.5059, -0.4222],\n",
            "        [ 0.0610,  0.3311,  0.4724,  0.3628],\n",
            "        [-0.5107, -0.7052, -0.4307,  0.5845],\n",
            "        [ 0.2322, -0.3975,  0.4793, -0.4975],\n",
            "        [-0.5695, -0.0712,  0.3605,  0.3991],\n",
            "        [-0.5728, -0.1069,  0.5449,  0.5655],\n",
            "        [ 0.3078,  0.3828,  0.4569, -0.3502],\n",
            "        [-0.4853, -0.8252, -0.4042,  0.2819],\n",
            "        [-0.3084,  0.6310, -0.1314, -0.4301],\n",
            "        [ 0.1922,  0.1616,  0.3053,  0.3367],\n",
            "        [-0.4965, -0.0162, -0.2046,  0.5846]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.4726, -0.2734, -0.3792,  0.0095,  0.5026, -0.1468, -0.3385,  0.2372,\n",
            "         0.2930,  0.3888, -0.1112,  0.1342, -0.0509,  0.0648, -0.3985, -0.0923],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.0824, -0.0023, -0.0494,  0.0088,  0.7526, -0.1208,  0.1642,  0.6776,\n",
            "         -0.3681,  0.2818,  0.0026, -0.5461,  0.5344, -0.5889, -0.1612,  0.3405],\n",
            "        [-0.3504, -0.2758, -0.1140, -0.3155,  0.1511, -0.4070, -0.0860,  0.1710,\n",
            "          0.1358, -0.1385,  0.1531, -0.1989,  0.5326,  0.3763,  0.0605, -0.3390],\n",
            "        [ 0.4091, -0.3532,  0.0196,  0.9285, -0.5775,  0.2372, -0.1398, -0.5609,\n",
            "         -0.0368, -0.2392, -0.5997,  0.3984, -0.5082,  0.1265,  0.1848, -0.3713],\n",
            "        [-0.0651,  0.1818, -0.1812,  0.2297, -0.2630, -0.0480,  0.2219, -0.3636,\n",
            "         -0.1761,  0.1220,  0.0845,  0.4101, -0.4086, -0.3970,  0.2462,  0.3416]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0085,  0.0910, -0.3428,  0.1589], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([1.1639, 1.1332, 0.8383, 1.2142], device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.1999, -0.2211, -0.2399, -0.1528], device='cuda:0',\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiywOH40Ahj8",
        "outputId": "147ef174-9c72-4701-fe51-2833210ec726"
      },
      "source": [
        "i = 0\n",
        "for param in model.parameters():\n",
        "  i = i + 1\n",
        "  if i == 2:\n",
        "    print(param)"
      ],
      "id": "kiywOH40Ahj8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.3437,  0.6721,  0.3051, -0.2518],\n",
            "        [-0.4575, -0.9761,  0.0482,  0.1917]], device='cuda:0',\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nGsmEsnRn7o",
        "outputId": "a788b25f-2ebc-4bef-dfb0-4c71b42fc289"
      },
      "source": [
        "i = 0\n",
        "for param in model.parameters():\n",
        "  i = i + 1\n",
        "  if i != 2:\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model.parameters():\n",
        "  print(param)"
      ],
      "id": "2nGsmEsnRn7o",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.4519, -0.1661, -1.5228,  0.3817]], device='cuda:0')\n",
            "Parameter containing:\n",
            "tensor([[ 0.3437,  0.6721,  0.3051, -0.2518],\n",
            "        [-0.4575, -0.9761,  0.0482,  0.1917]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.6851,  0.5488], device='cuda:0')\n",
            "Parameter containing:\n",
            "tensor([[ 0.2981,  0.2718, -0.4888,  0.3100],\n",
            "        [ 0.1397,  0.4743,  0.3300, -0.4556],\n",
            "        [-0.4754, -0.2412,  0.4391, -0.0833],\n",
            "        [ 0.2140, -0.2324,  0.4906, -0.2115]], device='cuda:0')\n",
            "Parameter containing:\n",
            "tensor([[ 0.3750,  0.0059, -0.2634,  0.2570],\n",
            "        [-0.2654,  0.1471, -0.1444, -0.0548],\n",
            "        [-0.4807, -0.2384,  0.2713, -0.1215],\n",
            "        [ 0.4980,  0.4008, -0.0234, -0.3337]], device='cuda:0')\n",
            "Parameter containing:\n",
            "tensor([[-0.1179, -0.4499, -0.2774, -0.0596],\n",
            "        [ 1.0474,  1.2953, -0.3747,  0.6117],\n",
            "        [-0.9368, -0.8702, -0.2733, -1.1846],\n",
            "        [-0.0218, -0.3942,  0.2557, -0.0646]], device='cuda:0')\n",
            "Parameter containing:\n",
            "tensor([[ 0.1129,  0.0349,  0.1316,  0.3174],\n",
            "        [-0.4234,  0.2725, -0.3305, -0.4131],\n",
            "        [-0.0756, -0.2103,  0.2203, -0.1788],\n",
            "        [-0.3911,  0.4588, -0.0339,  0.2110]], device='cuda:0')\n",
            "Parameter containing:\n",
            "tensor([[ 0.2960, -0.3800,  0.2712, -0.1860],\n",
            "        [-0.3815, -0.3158,  0.3079, -0.0816],\n",
            "        [-0.1900, -0.0055,  0.3908, -0.0895],\n",
            "        [ 0.0319,  0.6062, -0.5985, -0.2835],\n",
            "        [ 0.2902, -0.3319,  0.1671,  0.6924],\n",
            "        [ 0.0501,  0.4461,  0.5059, -0.4222],\n",
            "        [ 0.0610,  0.3311,  0.4724,  0.3628],\n",
            "        [-0.5107, -0.7052, -0.4307,  0.5845],\n",
            "        [ 0.2322, -0.3975,  0.4793, -0.4975],\n",
            "        [-0.5695, -0.0712,  0.3605,  0.3991],\n",
            "        [-0.5728, -0.1069,  0.5449,  0.5655],\n",
            "        [ 0.3078,  0.3828,  0.4569, -0.3502],\n",
            "        [-0.4853, -0.8252, -0.4042,  0.2819],\n",
            "        [-0.3084,  0.6310, -0.1314, -0.4301],\n",
            "        [ 0.1922,  0.1616,  0.3053,  0.3367],\n",
            "        [-0.4965, -0.0162, -0.2046,  0.5846]], device='cuda:0')\n",
            "Parameter containing:\n",
            "tensor([-0.4726, -0.2734, -0.3792,  0.0095,  0.5026, -0.1468, -0.3385,  0.2372,\n",
            "         0.2930,  0.3888, -0.1112,  0.1342, -0.0509,  0.0648, -0.3985, -0.0923],\n",
            "       device='cuda:0')\n",
            "Parameter containing:\n",
            "tensor([[ 0.0824, -0.0023, -0.0494,  0.0088,  0.7526, -0.1208,  0.1642,  0.6776,\n",
            "         -0.3681,  0.2818,  0.0026, -0.5461,  0.5344, -0.5889, -0.1612,  0.3405],\n",
            "        [-0.3504, -0.2758, -0.1140, -0.3155,  0.1511, -0.4070, -0.0860,  0.1710,\n",
            "          0.1358, -0.1385,  0.1531, -0.1989,  0.5326,  0.3763,  0.0605, -0.3390],\n",
            "        [ 0.4091, -0.3532,  0.0196,  0.9285, -0.5775,  0.2372, -0.1398, -0.5609,\n",
            "         -0.0368, -0.2392, -0.5997,  0.3984, -0.5082,  0.1265,  0.1848, -0.3713],\n",
            "        [-0.0651,  0.1818, -0.1812,  0.2297, -0.2630, -0.0480,  0.2219, -0.3636,\n",
            "         -0.1761,  0.1220,  0.0845,  0.4101, -0.4086, -0.3970,  0.2462,  0.3416]],\n",
            "       device='cuda:0')\n",
            "Parameter containing:\n",
            "tensor([ 0.0085,  0.0910, -0.3428,  0.1589], device='cuda:0')\n",
            "Parameter containing:\n",
            "tensor([1.1639, 1.1332, 0.8383, 1.2142], device='cuda:0')\n",
            "Parameter containing:\n",
            "tensor([-0.1999, -0.2211, -0.2399, -0.1528], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2XxHxD7v28E"
      },
      "source": [
        "model_transfer = copy.deepcopy(model)\n",
        "model_transfer = model_transfer.cuda()"
      ],
      "id": "B2XxHxD7v28E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tptowz6yBPQZ",
        "outputId": "58d00e8c-f2a8-43d4-e047-2f14eb152409"
      },
      "source": [
        "for param in model_transfer.parameters():\n",
        "  print(param)"
      ],
      "id": "tptowz6yBPQZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.4519, -0.1661, -1.5228,  0.3817]], device='cuda:0')\n",
            "Parameter containing:\n",
            "tensor([[ 0.3437,  0.6721,  0.3051, -0.2518],\n",
            "        [-0.4575, -0.9761,  0.0482,  0.1917]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.6851,  0.5488], device='cuda:0')\n",
            "Parameter containing:\n",
            "tensor([[ 0.2981,  0.2718, -0.4888,  0.3100],\n",
            "        [ 0.1397,  0.4743,  0.3300, -0.4556],\n",
            "        [-0.4754, -0.2412,  0.4391, -0.0833],\n",
            "        [ 0.2140, -0.2324,  0.4906, -0.2115]], device='cuda:0')\n",
            "Parameter containing:\n",
            "tensor([[ 0.3750,  0.0059, -0.2634,  0.2570],\n",
            "        [-0.2654,  0.1471, -0.1444, -0.0548],\n",
            "        [-0.4807, -0.2384,  0.2713, -0.1215],\n",
            "        [ 0.4980,  0.4008, -0.0234, -0.3337]], device='cuda:0')\n",
            "Parameter containing:\n",
            "tensor([[-0.1179, -0.4499, -0.2774, -0.0596],\n",
            "        [ 1.0474,  1.2953, -0.3747,  0.6117],\n",
            "        [-0.9368, -0.8702, -0.2733, -1.1846],\n",
            "        [-0.0218, -0.3942,  0.2557, -0.0646]], device='cuda:0')\n",
            "Parameter containing:\n",
            "tensor([[ 0.1129,  0.0349,  0.1316,  0.3174],\n",
            "        [-0.4234,  0.2725, -0.3305, -0.4131],\n",
            "        [-0.0756, -0.2103,  0.2203, -0.1788],\n",
            "        [-0.3911,  0.4588, -0.0339,  0.2110]], device='cuda:0')\n",
            "Parameter containing:\n",
            "tensor([[ 0.2960, -0.3800,  0.2712, -0.1860],\n",
            "        [-0.3815, -0.3158,  0.3079, -0.0816],\n",
            "        [-0.1900, -0.0055,  0.3908, -0.0895],\n",
            "        [ 0.0319,  0.6062, -0.5985, -0.2835],\n",
            "        [ 0.2902, -0.3319,  0.1671,  0.6924],\n",
            "        [ 0.0501,  0.4461,  0.5059, -0.4222],\n",
            "        [ 0.0610,  0.3311,  0.4724,  0.3628],\n",
            "        [-0.5107, -0.7052, -0.4307,  0.5845],\n",
            "        [ 0.2322, -0.3975,  0.4793, -0.4975],\n",
            "        [-0.5695, -0.0712,  0.3605,  0.3991],\n",
            "        [-0.5728, -0.1069,  0.5449,  0.5655],\n",
            "        [ 0.3078,  0.3828,  0.4569, -0.3502],\n",
            "        [-0.4853, -0.8252, -0.4042,  0.2819],\n",
            "        [-0.3084,  0.6310, -0.1314, -0.4301],\n",
            "        [ 0.1922,  0.1616,  0.3053,  0.3367],\n",
            "        [-0.4965, -0.0162, -0.2046,  0.5846]], device='cuda:0')\n",
            "Parameter containing:\n",
            "tensor([-0.4726, -0.2734, -0.3792,  0.0095,  0.5026, -0.1468, -0.3385,  0.2372,\n",
            "         0.2930,  0.3888, -0.1112,  0.1342, -0.0509,  0.0648, -0.3985, -0.0923],\n",
            "       device='cuda:0')\n",
            "Parameter containing:\n",
            "tensor([[ 0.0824, -0.0023, -0.0494,  0.0088,  0.7526, -0.1208,  0.1642,  0.6776,\n",
            "         -0.3681,  0.2818,  0.0026, -0.5461,  0.5344, -0.5889, -0.1612,  0.3405],\n",
            "        [-0.3504, -0.2758, -0.1140, -0.3155,  0.1511, -0.4070, -0.0860,  0.1710,\n",
            "          0.1358, -0.1385,  0.1531, -0.1989,  0.5326,  0.3763,  0.0605, -0.3390],\n",
            "        [ 0.4091, -0.3532,  0.0196,  0.9285, -0.5775,  0.2372, -0.1398, -0.5609,\n",
            "         -0.0368, -0.2392, -0.5997,  0.3984, -0.5082,  0.1265,  0.1848, -0.3713],\n",
            "        [-0.0651,  0.1818, -0.1812,  0.2297, -0.2630, -0.0480,  0.2219, -0.3636,\n",
            "         -0.1761,  0.1220,  0.0845,  0.4101, -0.4086, -0.3970,  0.2462,  0.3416]],\n",
            "       device='cuda:0')\n",
            "Parameter containing:\n",
            "tensor([ 0.0085,  0.0910, -0.3428,  0.1589], device='cuda:0')\n",
            "Parameter containing:\n",
            "tensor([1.1639, 1.1332, 0.8383, 1.2142], device='cuda:0')\n",
            "Parameter containing:\n",
            "tensor([-0.1999, -0.2211, -0.2399, -0.1528], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGezQIvb2FI7",
        "outputId": "88cf4c9e-da8e-4f0f-fb91-93ff2308bd3c"
      },
      "source": [
        "new_data = pd.read_csv(\"/content/drive/MyDrive/ML_final_project/rand_reuse_str-1_files-10_ent-500k_labeled.csv\", header = None)\n",
        "new_data = new_data.T.to_numpy()[1:6,:]\n",
        "window = 100\n",
        "new_data = np.hsplit(new_data, new_data.shape[1] / window)\n",
        "new_source_seq,new_target_seq, new_train_loader, new_val_loader = get_data_loader(new_data, batch_size=100)\n",
        "print(new_source_seq.shape)\n",
        "print(new_target_seq.shape)"
      ],
      "id": "HGezQIvb2FI7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([49998, 100, 4])\n",
            "torch.Size([49998, 100, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt80Cg5LJRZ8",
        "outputId": "5dc00898-5809-4806-9b21-d2ec6078b2a3"
      },
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "batch_size = 80\n",
        "num_epochs = 20\n",
        "learning_rate = 5e-5\n",
        "\n",
        "\n",
        "num_blocks = 1\n",
        "d_model = 4\n",
        "num_heads = 1\n",
        "d_ff = 4 * d_model\n",
        "dropout = 0.3\n",
        "\n",
        "label_classes = 2 \n",
        "MAX_LEN = 100\n",
        "\n",
        "new_source_seq, new_target_seq, new_train_loader, new_val_loader = get_data_loader(new_data, batch_size)\n",
        "\n",
        "model_transfer, loss_history = train(model_transfer, new_train_loader, new_val_loader, num_epochs, learning_rate)"
      ],
      "id": "jt80Cg5LJRZ8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "false Positive Rate is:  3.205068060196936e-05\n",
            "Train Epoch:   0 \t Loss: 0.161744 \t Val Acc: 75.484474\n",
            "false Positive Rate is:  3.20508552249521e-05\n",
            "Train Epoch:   1 \t Loss: 0.164496 \t Val Acc: 75.484070\n",
            "false Positive Rate is:  3.204683162039146e-05\n",
            "Train Epoch:   2 \t Loss: 0.159868 \t Val Acc: 75.493546\n",
            "false Positive Rate is:  3.2044521503848955e-05\n",
            "Train Epoch:   3 \t Loss: 0.155554 \t Val Acc: 75.498993\n",
            "false Positive Rate is:  3.204366294085048e-05\n",
            "Train Epoch:   4 \t Loss: 0.159463 \t Val Acc: 75.500801\n",
            "false Positive Rate is:  3.204435051884502e-05\n",
            "Train Epoch:   5 \t Loss: 0.162337 \t Val Acc: 75.499191\n",
            "false Positive Rate is:  2.9375947633525357e-05\n",
            "Train Epoch:   6 \t Loss: 0.158812 \t Val Acc: 75.494354\n",
            "false Positive Rate is:  2.670726098585874e-05\n",
            "Train Epoch:   7 \t Loss: 0.157483 \t Val Acc: 75.489311\n",
            "false Positive Rate is:  2.4037626644712873e-05\n",
            "Train Epoch:   8 \t Loss: 0.158042 \t Val Acc: 75.486084\n",
            "false Positive Rate is:  2.403223334113136e-05\n",
            "Train Epoch:   9 \t Loss: 0.153126 \t Val Acc: 75.503021\n",
            "false Positive Rate is:  2.403582948318217e-05\n",
            "Train Epoch:  10 \t Loss: 0.150075 \t Val Acc: 75.491730\n",
            "false Positive Rate is:  2.1364154235925525e-05\n",
            "Train Epoch:  11 \t Loss: 0.152353 \t Val Acc: 75.495560\n",
            "false Positive Rate is:  2.1363584892242216e-05\n",
            "Train Epoch:  12 \t Loss: 0.163561 \t Val Acc: 75.497375\n",
            "false Positive Rate is:  1.8693484889809042e-05\n",
            "Train Epoch:  13 \t Loss: 0.152140 \t Val Acc: 75.496170\n",
            "false Positive Rate is:  2.136284274456557e-05\n",
            "Train Epoch:  14 \t Loss: 0.153473 \t Val Acc: 75.500000\n",
            "false Positive Rate is:  2.1364439817261882e-05\n",
            "Train Epoch:  15 \t Loss: 0.152312 \t Val Acc: 75.494354\n",
            "false Positive Rate is:  2.136432522092946e-05\n",
            "Train Epoch:  16 \t Loss: 0.154193 \t Val Acc: 75.494759\n",
            "false Positive Rate is:  2.1360276150517166e-05\n",
            "Train Epoch:  17 \t Loss: 0.143442 \t Val Acc: 75.509071\n",
            "false Positive Rate is:  2.1363241103244945e-05\n",
            "Train Epoch:  18 \t Loss: 0.150345 \t Val Acc: 75.498589\n",
            "false Positive Rate is:  2.1368663510656916e-05\n",
            "Train Epoch:  19 \t Loss: 0.152758 \t Val Acc: 75.479431\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-voS3WoTyCO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17446b31-203e-47df-be27-b92bde04eb38"
      },
      "source": [
        "for batch, data in enumerate(new_val_loader):\n",
        "  data = [d.cuda() for d in data]\n",
        "  target = data[1]\n",
        "  pred = model.predict(data[0])\n",
        "  pred_new = model_transfer.predict(data[0])\n",
        "print(target)"
      ],
      "id": "8-voS3WoTyCO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[1],\n",
            "         [1],\n",
            "         [0],\n",
            "         ...,\n",
            "         [1],\n",
            "         [1],\n",
            "         [1]],\n",
            "\n",
            "        [[1],\n",
            "         [1],\n",
            "         [0],\n",
            "         ...,\n",
            "         [0],\n",
            "         [1],\n",
            "         [1]],\n",
            "\n",
            "        [[1],\n",
            "         [1],\n",
            "         [1],\n",
            "         ...,\n",
            "         [1],\n",
            "         [1],\n",
            "         [1]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[1],\n",
            "         [1],\n",
            "         [1],\n",
            "         ...,\n",
            "         [0],\n",
            "         [1],\n",
            "         [1]],\n",
            "\n",
            "        [[0],\n",
            "         [1],\n",
            "         [1],\n",
            "         ...,\n",
            "         [0],\n",
            "         [1],\n",
            "         [1]],\n",
            "\n",
            "        [[1],\n",
            "         [0],\n",
            "         [1],\n",
            "         ...,\n",
            "         [1],\n",
            "         [1],\n",
            "         [1]]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}